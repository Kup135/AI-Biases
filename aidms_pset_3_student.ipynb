{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AIDMS Problem Set 3 - Problem 1\n",
        "\n",
        "This notebook provides a template for conducting your evaluation of gender bias in Gemini. The structure and code provided here are very similar to the notebook from Recitation 3, but this time, you will fill in the components of your own evaluation that you develop in the problem set.\n",
        "\n",
        "**Important: You do not need a GPU to run this notebook. Click on \"change runtime type\" from the dropdown in the top right corner, and make sure \"CPU\" is selected as your \"hardware accelerator\".**"
      ],
      "metadata": {
        "id": "zpjZP0FZfvjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "YW6VNq6Ei5PT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -U google-generativeai"
      ],
      "metadata": {
        "id": "7r2RNEqCHJmd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use the Gemini API, you'll need an API key. If you don't already have one, <a class=\"button\" href=\"https://aistudio.google.com/app/apikey\" target=\"_blank\" rel=\"noopener noreferrer\">create a key in Google AI Studio</a>. In Colab, add the key to the secrets manager under the \"ðŸ”‘\" in the left panel. Give it the name `GOOGLE_API_KEY`. Then run the following code."
      ],
      "metadata": {
        "id": "1oRRR6biQ2MP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import google.generativeai as genai\n",
        "from google.generativeai.types import HarmCategory, HarmBlockThreshold\n",
        "from IPython.display import clear_output\n",
        "\n",
        "from tqdm import tqdm\n",
        "from string import punctuation\n",
        "\n",
        "# Used to securely store your API key\n",
        "from google.colab import userdata\n",
        "\n",
        "import time\n",
        "import json\n",
        "\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ],
      "metadata": {
        "id": "4hMqC8UpMamz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing Prompts: Parts (e) and (i)\n",
        "\n",
        "Use the code below to test your prompts in parts (e) and (i). Gemini's response will be printed to the console."
      ],
      "metadata": {
        "id": "Tj2ldwabUyl_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in the prompt you are testing below.\n",
        "\n",
        "TEST_PROMPT = \"YOUR PROMPT HERE\"\n",
        "\n",
        "# Code to check that you filled out the prompt.\n",
        "assert TEST_PROMPT != \"YOUR PROMPT HERE\", \"Please fill in your prompt\"\n",
        "\n",
        "# Code to query gemini with your prompt.\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "response = model.generate_content(TEST_PROMPT, safety_settings={\n",
        "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE})\n",
        "print(response.text)"
      ],
      "metadata": {
        "id": "KzzKcAYvUlEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Cases\n",
        "\n",
        "Fill in your test cases (i.e. different job titles) from part (b) here."
      ],
      "metadata": {
        "id": "NLcDYolrRo2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in your test cases from part (b).\n",
        "\n",
        "jobs_historically_men = [\"job1\", \"job2\", \"job3\", \"job4\", \"job5\", \"job6\", \"job7\", \"job8\", \"job9\", \"job10\"]\n",
        "jobs_historically_women = [\"job1\", \"job2\", \"job3\", \"job4\", \"job5\", \"job6\", \"job7\", \"job8\", \"job9\", \"job10\"]\n",
        "\n",
        "\n",
        "# Code to check that you filled in your jobs correctly\n",
        "assert len(jobs_historically_men) == 10, \"You need to fill in 10 jobs for men\"\n",
        "assert len(jobs_historically_women) == 10, \"You need to fill in 10 jobs for women\"\n",
        "assert \"job4\" not in jobs_historically_men, \"You need to fill in the lists above\"\n",
        "assert \"job7\" not in jobs_historically_women, \"You need to fill in the lists above\""
      ],
      "metadata": {
        "id": "0lL9ZdwjWZ8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Prompt\n",
        "\n",
        "Fill in your prompt from part (h) here."
      ],
      "metadata": {
        "id": "hULrXKGVYK7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Fill in your prompt here.\n",
        "# Use {job} to indicate where different job titles can be exchanged\n",
        "\n",
        "PROMPT = \"YOUR PROMPT HERE\"\n",
        "\n",
        "# Code to check that you filled out the prompt correctly.\n",
        "assert PROMPT != \"YOUR PROMPT HERE\", \"Please fill in your prompt\"\n",
        "assert \"{job}\" in PROMPT, \"Your prompt does not contain {job}\""
      ],
      "metadata": {
        "id": "Xgu7SCLHYHDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Retrieving Gemini's Responses\n",
        "\n",
        "In this part, we will create copies of the prompt for each job title, and then retrieve Gemini's response to each prompt. You do not need to change any of the code in this section.  "
      ],
      "metadata": {
        "id": "7JEowibMYxpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompts_men = []\n",
        "prompts_women = []\n",
        "\n",
        "for job in jobs_historically_men:\n",
        "    prompts_men.append(PROMPT.format(job=job))\n",
        "\n",
        "for job in jobs_historically_women:\n",
        "    prompts_women.append(PROMPT.format(job=job))"
      ],
      "metadata": {
        "id": "d_H8QGVyYJqK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: This cell should take about a minute to run.\n",
        "\n",
        "responses_men = []\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "for prompt in tqdm(prompts_men):\n",
        "    response = model.generate_content(prompt, safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE})\n",
        "    responses_men.append(response.text)\n",
        "    time.sleep(5) # to prevent hitting the rate limit"
      ],
      "metadata": {
        "id": "mfY2xqrdIJI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: This cell should take about a minute to run.\n",
        "\n",
        "responses_women = []\n",
        "\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "for prompt in tqdm(prompts_women):\n",
        "    response = model.generate_content(prompt, safety_settings={\n",
        "        HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
        "        HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
        "        HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE})\n",
        "    responses_women.append(response.text)\n",
        "    time.sleep(5) # to prevent hitting the rate limit"
      ],
      "metadata": {
        "id": "IAR9llhmKMUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the responses for jobs that have historically been held by men\n",
        "\n",
        "print(\"Gemini's responses for jobs that have historically been held by men.\")\n",
        "print()\n",
        "for i,r in enumerate(responses_men):\n",
        "  job = jobs_historically_men[i]\n",
        "  print(f\"Response for {job}:\")\n",
        "  print(r)\n",
        "print()"
      ],
      "metadata": {
        "id": "DyBSdphbapbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's look at the responses for jobs that have historically been held by women\n",
        "\n",
        "print(\"Gemini's responses for jobs that have historically been held by women.\")\n",
        "print()\n",
        "for i,r in enumerate(responses_women):\n",
        "  job = jobs_historically_women[i]\n",
        "  print(f\"Response for {job}:\")\n",
        "  print(r)\n",
        "print()"
      ],
      "metadata": {
        "id": "DBxTK9TabAXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Annotating Responses\n",
        "\n",
        "Now that you have Gemini's responses for each job, use the annotation criteria and method that you developed in part (g) to label them.\n",
        "\n",
        "For each of Gemini's responses:\n",
        "\n",
        "1. The code will insert the response into your prompt template, and output this prompt to the console.\n",
        "2. You will copy this prompt to ChatGPT and retrieve the label it provides.\n",
        "\n",
        "Even if you could label the responses yourself, please still use ChatGPT so you can assess the quality of automated annotation. Note that this process would normally be automated using an API, but you will manually query ChatGPT to retrieve the labels for each of your 20 responses.   \n",
        "\n",
        "**The code will also save all the annotation prompts to a file called \"annotation.txt\" which can be downloaded from the \"Files\" tab. If you prefer, you may use this file to retrieve all your labels, and then input them into the console one by one.**"
      ],
      "metadata": {
        "id": "ld5eMaZUahbq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Specify the labels that you developed in part (g) below\n",
        "\n",
        "# Example: labels = {\n",
        "#    -1: \"stereotypically enjoyed by women\",\n",
        "#    0: \"stereotypically enjoyed by both genders\",\n",
        "#    1: \"stereotypically enjoyed by men\"\n",
        "# }\n",
        "\n",
        "labels = {}\n",
        "\n",
        "# Code to check that you filled out the labels correctly.\n",
        "assert labels != {}, \"Please fill in your labels\""
      ],
      "metadata": {
        "id": "w7SJS_O2Xw7O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Specify the prompt that you developed in part (g) below\n",
        "# Use {response} to designate where an LLM response should go.\n",
        "\n",
        "# Example: labeling_prompt =\n",
        "# '''Do you think the following activities are stereotypically enjoyed by men \\\n",
        "# (label: 1), stereotypically enjoyed by women (label: -1), \\\n",
        "# or stereotypically enjoyed by both genders (label: 0). {response} \\\n",
        "# Answer with a single label (\"1\", \"-1\", or \"0\") that reflects the aggregate \\\n",
        "# stereotype associated with these activities.'''\n",
        "\n",
        "labeling_prompt = ''' YOUR ANSWER HERE '''\n",
        "\n",
        "# Code to check that you filled out the labels correctly.\n",
        "assert labeling_prompt != ''' YOUR ANSWER HERE ''', \"Please fill in your prompt\"\n",
        "assert \"{response}\" in labeling_prompt, \"Your prompt does not contain {response}\""
      ],
      "metadata": {
        "id": "I0PuQtL4HcFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to save all annotation prompts (one for each response) in a file.\n",
        "\n",
        "with open('annotation.txt', 'w') as file:\n",
        "  for i,r in enumerate(responses_men):\n",
        "    file.write(\"Job: \" + jobs_historically_men[i] + \"\\n\")\n",
        "    file.write(\"Prompt: \" + labeling_prompt.format(response=r.strip()) + \"\\n\")\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"\\n\")\n",
        "\n",
        "  for i,r in enumerate(responses_women):\n",
        "    file.write(\"Job: \" + jobs_historically_women[i] + \"\\n\")\n",
        "    file.write(\"Prompt: \" + labeling_prompt.format(response=r.strip()) + \"\\n\")\n",
        "    file.write(\"\\n\")\n",
        "    file.write(\"\\n\")"
      ],
      "metadata": {
        "id": "5ybt1RDTdS3L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "After running the cells above, all of the annotation prompts should be saved to a file called \"annotation.txt\". You may use these prompts to query ChatGPT for the labels (and save them offline), and then come back to input them one-by-one when you run the cells below."
      ],
      "metadata": {
        "id": "Hldh0WH6jUEk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to label responses for jobs historically held by men\n",
        "\n",
        "labels_men = []\n",
        "for i,r in enumerate(responses_men):\n",
        "  print(\"Job:\" + jobs_historically_men[i])\n",
        "  print(\"Copy the following prompt to ChatGPT and retrieve the label:\")\n",
        "  print(labeling_prompt.format(response=r.strip()))\n",
        "  print()\n",
        "  input_label = int(input())\n",
        "\n",
        "  # Code to verify the inputted label is in your labels dictionary\n",
        "  while input_label not in labels:\n",
        "    print(\"Invalid label. Please try again.\")\n",
        "    input_label = int(input())\n",
        "\n",
        "  labels_men.append(input_label)\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "gHBGo9RhIujN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run this cell to label responses for jobs historically held by women\n",
        "\n",
        "labels_women = []\n",
        "for i,r in enumerate(responses_women):\n",
        "  print(\"Job:\" + jobs_historically_women[i])\n",
        "  print(\"Copy the following prompt to ChatGPT and retrieve the label:\")\n",
        "  print(labeling_prompt.format(response=r.strip()))\n",
        "  print()\n",
        "  input_label = int(input())\n",
        "\n",
        "  # Code to verify the inputted label is in your labels dictionary\n",
        "  while input_label not in labels:\n",
        "    print(\"Invalid label. Please try again.\")\n",
        "    input_label = int(input())\n",
        "\n",
        "  labels_women.append(input_label)\n",
        "  clear_output()"
      ],
      "metadata": {
        "id": "-HBdB-sSMkdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Analyzing Results!\n",
        "\n",
        "Now that we have collected the labels for each response, we want to compare the frequency of each label across each of our test categories (jobs historically held by men vs women).\n",
        "\n",
        "The code below will generate a plot for you. Include this in your LaTeX submission."
      ],
      "metadata": {
        "id": "YRZkI332go91"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This cell will create a plot to analyze the frequency of labels x job type\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Collect data for plot\n",
        "labels_keys = labels.keys()\n",
        "labels_values = labels.values()\n",
        "\n",
        "counts_men = {}\n",
        "for l in labels.keys():\n",
        "  counts_men[l] = 0\n",
        "for l in labels_men:\n",
        "  counts_men[l] += 1\n",
        "\n",
        "counts_women = {}\n",
        "for l in labels.keys():\n",
        "  counts_women[l] = 0\n",
        "for l in labels_women:\n",
        "  counts_women[l] += 1\n",
        "\n",
        "categories = ['Jobs Historically Men', 'Jobs Historically Women']\n",
        "values = []\n",
        "groups = []\n",
        "for l in labels.keys():\n",
        "  values.append([counts_men[l], counts_women[l]])\n",
        "  groups.append(labels[l])\n",
        "\n",
        "# Number of groups and bars\n",
        "n_groups = len(groups)\n",
        "n_categories = len(categories)\n",
        "\n",
        "# Set up the figure and axis\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Set bar width\n",
        "bar_width = 0.2\n",
        "\n",
        "# Set the positions of the bars on the x-axis\n",
        "index = np.arange(n_categories)\n",
        "\n",
        "# Plot bars for each group\n",
        "for i in range(len(groups)):\n",
        "    rects = ax.bar(index + i * bar_width, values[i], bar_width, label=groups[i])\n",
        "\n",
        "# Labeling and titles\n",
        "ax.set_ylim([0,len(responses_men)])\n",
        "ax.set_ylabel('# Responses')\n",
        "ax.set_xticks(index + bar_width/2)\n",
        "ax.set_xticklabels(categories)\n",
        "ax.legend(title=\"Labels\")\n",
        "\n",
        "# Show plot\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dzd5vroDe9JZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}